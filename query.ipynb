{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'किस तरह के किरदार और कहानी तत्व रचनाकारों और फिल्म निर्माताओं को आकर्षित करते हैं?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext as ft\n",
    "# Loding model for Hindi.\n",
    "embed_model = ft.load_model('wiki.hi.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Filter, FieldCondition, Range\n",
    "\n",
    "# hits = client.search(\n",
    "#    collection_name=\"my_collection\",\n",
    "#    query_vector=embed_model.get_sentence_vector(query).tolist(),\n",
    "#    query_filter=Filter(\n",
    "#       must=[  # These conditions are required for search results\n",
    "#             FieldCondition(\n",
    "#                key='rand_number',  # Condition based on values of `rand_number` field.\n",
    "#                range=Range(\n",
    "#                   gte=3  # Select only those results where `rand_number` >= 3\n",
    "#                )\n",
    "#             )\n",
    "#       ]\n",
    "#    ),\n",
    "#    limit=5  # Return 5 closest points\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "hits = client.search(\n",
    "collection_name=\"my_collection\",\n",
    "query_vector= embed_model.get_sentence_vector(query).tolist(),\n",
    "limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To attract screenwriters and filmmakers, production houses and studios use various strategies. Some common methods are:\\n\\n1. Offering compelling stories and scripts: Production houses create a pool of high-quality scripts that cater to the current market trends and audience preferences. They often collaborate with established writers or provide opportunities for new talent to write engaging stories.\\n\\n2. Providing adequate resources and facilities: A well-equipped studio, modern technology, experienced technicians, and ample budget are some essential factors that can attract skilled professionals.\\n\\n3. Famous directors and actors: The involvement of popular directors and actors in a project can create excitement and generate interest among screenwriters and filmmakers.\\n\\n4. Lucrative deals and packages: Production houses may offer attractive remuneration packages, royalties, and profit-sharing arrangements to attract talent.\\n\\n5. Creative freedom and collaboration: Allowing artists to have creative control over their projects or collaborating with them closely during the development process can encourage them to join a production house.\\n\\n6. Building a strong team: Creating an environment where talented individuals thrive and support each other can make a production house an attractive place to work.\\n\\n7. Offering growth opportunities: Providing training, workshops, and mentorship programs can help nurture new talent while retaining the expertise of experienced professionals.\\n\\n8. Reputation and recognition: A strong reputation for producing high-quality films or shows can attract top talent in the industry.\\n\\n9. Flexibility: Being open to different ideas and perspectives, as well as offering flexible working arrangements, can create a welcoming environment for screenwriters and filmmakers.\\n\\n10. Marketing and distribution: Having a solid marketing and distribution strategy in place can ensure that projects reach a wider audience, increasing the potential for success and recognition.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(query+'you can only reply in hindi, english not allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(question):\n",
    " # Searching for relevant hits in the 'speech_collection'\n",
    " hits = client.search(\n",
    " collection_name=\"my_collection\",\n",
    " query_vector= embed_model.get_sentence_vector(question).tolist(),\n",
    " limit=10,\n",
    " )\n",
    " # Creating context from the hits\n",
    " context = ''\n",
    " for hit in hits:\n",
    "    context += hit.payload['page_content'] + '\\n'\n",
    " # Constructing the prompt\n",
    " prompt = f\"\"\"<s>[INST] आप एक सम्मानीय सहायक हैं। आपका काम नीचे दिए गए संदर्भ से प्रश्नों का उत्तर देना है।\n",
    " संदर्भ: {context}\n",
    " प्रश्न: {question} [/INST] </s>\n",
    " \"\"\"\n",
    " # Generating text using the GPT model\n",
    " sequences = pipeline(\n",
    " prompt,\n",
    " do_sample=True,\n",
    " temperature=0.7,\n",
    " top_k=50,\n",
    " top_p=0.95,\n",
    " num_return_sequences=1,\n",
    " )\n",
    " return sequences[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       # Create the custom chain\n",
    "       if llm is not None and db is not None:   \n",
    "              chain=ConversationalRetrievalChain.from_llm(llm=llm,retriever=retriever)\t\n",
    "       else:     \n",
    "              print(\"LLM or Vector Database not initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
